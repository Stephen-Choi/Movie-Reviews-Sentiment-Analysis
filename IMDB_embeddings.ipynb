{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h1>Embeddings</h1>\n",
    "\n",
    "This notebook was used to practice practical applications of word embeddings for deep learning."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>review</th>\n",
       "      <th>sentiment</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>I went and saw this movie last night after bei...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Actor turned director Bill Paxton follows up h...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>As a recreational golfer with some knowledge o...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>I saw this film in a sneak preview, and it is ...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>Bill Paxton has taken the true story of the 19...</td>\n",
       "      <td>1</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                              review  sentiment\n",
       "0  I went and saw this movie last night after bei...          1\n",
       "1  Actor turned director Bill Paxton follows up h...          1\n",
       "2  As a recreational golfer with some knowledge o...          1\n",
       "3  I saw this film in a sneak preview, and it is ...          1\n",
       "4  Bill Paxton has taken the true story of the 19...          1"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df = pd.read_csv('movie_review.csv', encoding='utf-8')\n",
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000, 2)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: This dataset is contains 25000 polar movie reviews for training and 25000 for testing. The sentiments are labelled as 1 for positive sentiment or 0 for negative sentiment."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Check the length of reviews for later use in the embeddings</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_reviews = df['review'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_lengths = [len(review.split()) for review in vocab]    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 87,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2470"
      ]
     },
     "execution_count": 87,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(review_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "231.15694"
      ]
     },
     "execution_count": 88,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(review_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 89,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "171.3422838351246"
      ]
     },
     "execution_count": 89,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(review_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 90,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "173.0"
      ]
     },
     "execution_count": 90,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.median(review_lengths)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "plt.hist(review_lengths, bins=40)  # arguments are passed to np.histogram\n",
    "plt.title(\"Word Lengths of Reviews\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 93,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'whiskers': [<matplotlib.lines.Line2D at 0xb8782af98>,\n",
       "  <matplotlib.lines.Line2D at 0xb87836320>],\n",
       " 'caps': [<matplotlib.lines.Line2D at 0xb87836668>,\n",
       "  <matplotlib.lines.Line2D at 0xb878369b0>],\n",
       " 'boxes': [<matplotlib.lines.Line2D at 0xb8782ae48>],\n",
       " 'medians': [<matplotlib.lines.Line2D at 0xb87836cf8>],\n",
       " 'fliers': [<matplotlib.lines.Line2D at 0xb8783f080>],\n",
       " 'means': []}"
      ]
     },
     "execution_count": 93,
     "metadata": {},
     "output_type": "execute_result"
    },
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAD8CAYAAAB+UHOxAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAFDpJREFUeJzt3XFsXfV99/H3145JkMkgiLRiGB6qKTwyj6UHWguqNoIaNAL8Q/ZHpbrSEjWGDNRYnooUMfwHbFNQFAGP0mggMcUikcAIaayNBIwnA6uVlaeMZEUQ8NMRdR0YEGQLtOQiB8f57g+fBAeC42MnvrbP+yVd3Xu//h3f75Vsf3zPOb/ficxEklQ9DfVuQJJUHwaAJFWUASBJFWUASFJFGQCSVFEGgCRVlAEgSRVlAEhSRRkAklRRi+rdwGQuuuiivPzyy+vdhiTNK/v27fvPzFx+unFzOgAuv/xy9u7dW+82JGleiYj/mMo4dwFJUkUZAJJUUacNgIi4NCIGImIoIt6IiJ6ifn9EvBsRrxa3Wyds81cRcSAifhMRqybUby5qByLinrPzliRJUzGVYwBHgbsz818jYimwLyJ2F1/7P5n54MTBEXEl8APgfwF/DPxzRFxRfPnvgD8FhoFXImJXZr55Jt6IJKmc0wZAZr4PvF88/iQihoBLJtnkNuCpzDwC/HtEHACuKb52IDN/CxARTxVjDQBJqoNSxwAi4nLgauDlorQhIl6LiL6IWFbULgHembDZcFH7qro0r/T399PW1kZjYyNtbW309/fXuyVpWqYcABFxHvAPwF9m5h+AR4E/Aa5i/BPCQ8eHnmLznKT+xddZHxF7I2LvwYMHp9qeNCv6+/vp7e1l27ZtjIyMsG3bNnp7ew0BzUtTCoCIaGL8j/8TmfkMQGZ+kJljmXkM+Hs+380zDFw6YfMW4L1J6ifJzMcysz0z25cvP+08BmlWbdq0ie3bt9PR0UFTUxMdHR1s376dTZs21bs1qbSpnAUUwHZgKDMfnlC/eMKwPwP2F493AT+IiMUR8Q1gBfAvwCvAioj4RkScw/iB4l1n5m1Is2NoaIiVK1eeVFu5ciVDQ0N16kiavqmcBfRd4M+B1yPi1aJ2L9AZEVcxvhvnd8BfAGTmGxHxNOMHd48CP87MMYCI2AC8ADQCfZn5xhl8L9JZ19rayuDgIB0dHSdqg4ODtLa21rEraXqmchbQIKfef//cJNtsAr70mTgzn5tsO2mu6+3tpauri+3bt7Ny5UoGBwfp6upyF5DmpTm9FpA013R2dgLQ3d3N0NAQra2tbNq06URdmk8i80sn4swZ7e3t6WJwklROROzLzPbTjXMtIEmqKANAkirKAJCkijIAJKmiDABJqigDQJIqygCQpIoyACSpogwAqSSvB6CFwqUgpBKOXw/gi2sBAS4HoXnHpSCkEtra2ti2bdtJq4EODAzQ3d3N/v37J9lSmj1TXQrCAJBKaGxsZGRkhKamphO10dFRlixZwtjYWB07kz7nWkDSWXD8egATeT0AzVcGgFTC8esBDAwMMDo6ysDAAF1dXfT29ta7Nak0DwJLJXg9AC0kHgOQpAXGYwCSpEkZAJJUUQaAJFWUASBJFWUASCW5FpAWCgNAKqG/v5+enh5qtRqZSa1Wo6enxxDQvGQASCVs3LiRxsZG+vr6OHLkCH19fTQ2NrJx48Z6tyaVZgBIJQwPD7Nz5046Ojpoamqio6ODnTt3Mjw8XO/WpNIMAEmqKANAKqGlpYW1a9eetBbQ2rVraWlpqXdrUmkGgFTCli1bOHr0KOvWrWPJkiWsW7eOo0ePsmXLlnq3JpVmAEgldHZ2snXrVpqbmwFobm5m69atLganecnF4CRpgTlji8FFxKURMRARQxHxRkT0FPULI2J3RLxV3C8r6hERP42IAxHxWkR8c8L3WluMfysi1s7kDUqSZmYqu4COAndnZivwbeDHEXElcA/wYmauAF4sngPcAqwobuuBR2E8MID7gGuBa4D7joeGJGn2nTYAMvP9zPzX4vEnwBBwCXAbsKMYtgNYXTy+DdiZ434FXBARFwOrgN2ZeSgzPwJ2Azef0XcjSZqyUgeBI+Jy4GrgZeDrmfk+jIcE8LVi2CXAOxM2Gy5qX1WXJNXBlAMgIs4D/gH4y8z8w2RDT1HLSepffJ31EbE3IvYePHhwqu1JkkqaUgBERBPjf/yfyMxnivIHxa4divsPi/owcOmEzVuA9yapnyQzH8vM9sxsX758eZn3IkkqYSpnAQWwHRjKzIcnfGkXcPxMnrXAzyfU1xRnA30b+H2xi+gF4KaIWFYc/L2pqEmS6mDRFMZ8F/hz4PWIeLWo3QtsBp6OiC7gbeD7xdeeA24FDgCfAj8CyMxDEfG3wCvFuL/JzENn5F1IkkpzIpgkLTBnbCKYJGlhMgAkqaIMAEmqKANAkirKAJCkijIApJL6+/tpa2ujsbGRtrY2+vv7692SNC0GgFRCf38/PT091Go1AGq1Gj09PYaA5iUDQCph48aNLFq0iL6+PkZGRujr62PRokVs3Lix3q1JpRkAUgnDw8Ps2LGDjo4Ompqa6OjoYMeOHQwPD9e7Nak0A0CSKsoAkEpoaWlhzZo1DAwMMDo6ysDAAGvWrKGlpaXerUmlGQBSCVu2bGFsbIx169axePFi1q1bx9jYGFu2bKl3a1JpBoBUQmdnJ1u3bqW5uZmIoLm5ma1bt9LZ2Vnv1qTSDABJqigDQCrBeQBaSAwAqQTnAWghMQCkEpwHoIXEAJCkijIApBKcB6CFxACQSnAegBYSA0AqwXkAWkgiM+vdw1dqb2/PvXv31rsNSZpXImJfZrafbpyfACSpogwASaooA0AqyUtCaqFYVO8GpPmkv7+f3t5etm/fzsqVKxkcHKSrqwvAA8GadzwILJXQ1tbGtm3b6OjoOFEbGBigu7ub/fv317Ez6XNTPQhsAEglNDY2MjIyQlNT04na6OgoS5YsYWxsrI6dSZ/zLCDpLGhtbWVwcPCk2uDgIK2trXXqSJo+A0Aqobe3l66urpOWgujq6qK3t7ferUmlGQBSCZ2dnaxYsYIbb7yRc845hxtvvJEVK1Z4AFjz0mkDICL6IuLDiNg/oXZ/RLwbEa8Wt1snfO2vIuJARPwmIlZNqN9c1A5ExD1n/q1IZ193dzcvvfQSDz74ILVajQcffJCXXnqJ7u7uercmlXbag8ARcR1wGNiZmW1F7X7gcGY++IWxVwL9wDXAHwP/DFxRfPnfgD8FhoFXgM7MfHOy1/YgsOaaJUuW8MADD/CTn/zkRO3hhx/m3nvvZWRkpI6dSZ87YweBM/OXwKEpvu5twFOZeSQz/x04wHgYXAMcyMzfZuZnwFPFWGleOXLkCHfeeedJtTvvvJMjR47UqSNp+mZyDGBDRLxW7CJaVtQuAd6ZMGa4qH1VXZpXFi9ezPr160+aCbx+/XoWL15c79ak0qYbAI8CfwJcBbwPPFTU4xRjc5L6l0TE+ojYGxF7Dx48OM32pLPj+uuv54knnuC6667j0KFDXHfddTzxxBNcf/319W5NKm1aAZCZH2TmWGYeA/6e8V08MP6f/aUThrYA701SP9X3fiwz2zOzffny5dNpTzpr3n33XVavXk1fXx8XXHABfX19rF69mnfffbferUmlTWstoIi4ODPfL57+GXD8DKFdwJMR8TDjB4FXAP/C+CeAFRHxDeBd4AfAD2fSuFQPQ0ND/PrXvz7lTGBpvjltAEREP/A94KKIGAbuA74XEVcxvhvnd8BfAGTmGxHxNPAmcBT4cWaOFd9nA/AC0Aj0ZeYbZ/zdSGfZ8ZnAE9cCciaw5qvTBkBmnmqGy/ZJxm8CNp2i/hzwXKnupDnm+EzgL64GumnTl37kpTnP5aClEjo7O9mzZw+33HILR44cYfHixdxxxx3OBNa85FIQUgn9/f08++yzPP/883z22Wc8//zzPPvss14URvOSy0FLJbS1tbF69Wp+9rOfMTQ0RGtr64nnXg9Ac4XXA5DOgoaGBs477zxGRkYYHR2lqamJJUuWcPjwYY4dO1bv9iTA6wFIZ0VDQwO1Wo3NmzefdN/Q4K+S5h9/aqUSxsbGOP/887n66qtpamri6quv5vzzz/dqYJqXDACppNtvv53u7m6WLFlCd3c3t99+e71bkqbFAJBKWLRoEY888gi1Wg2AWq3GI488wqJFnlGt+ccAkEq44YYbqNVqvP322xw7doy3336bWq3GDTfcUO/WpNIMAKmEN998k3PPPZfGxkYAGhsbOffcc3nzzUmvbSTNSQaAVMLw8DA9PT1cccUVNDQ0cMUVV9DT08Pw8HC9W5NKMwCkkk51DECajwwAqYSGhgYOHz5Md3c3n3zyCd3d3Rw+fNh5AJqX/KmVSjh27BhLly5l27ZtJ907C1jzkQEglXTXXXfR3NwMQHNzM3fddVedO5Kmx5OXpRJaWlp4/PHHefLJJ09cD+CHP/whLS0t9W5NKs1PAFIJW7Zs4dNPP2XVqlWcc845rFq1ik8//ZQtW7bUuzWpND8BSCV99tlnjI6OAuPXAz4+J0Cab/wEIJWwYcMGRkdHeeihh6jVajz00EOMjo6yYcOGercmleb1AKQSIoLvfOc77Nu378QlIb/1rW+xZ88e5vLvkqrF6wFIZ8mePXtOLP88NjbGnj176tyRND0GgDQNd9xxBx9//DF33HFHvVuRps0AkEqKCJ555hkuuOACnnnmGSKi3i1J02IASCVde+21fPzxxwB8/PHHXHvttXXuSJoeA0AqobGxkZdffpkHHniAWq3GAw88wMsvv+ypoJqXDACphLvuuovM5O6776a5uZm7776bzHQ5CM1LBoBUwi9+8YtSdWkuMwCkEl5//XUAli5dSkNDA0uXLj2pLs0nBoBUUkNDAyMjIxw7doyRkRGvBaB5y59cqaRjx46xefNmarUamzdv9loAmrdcCkIq4fg5/xFBZp64B1wKQnPGGVsKIiL6IuLDiNg/oXZhROyOiLeK+2VFPSLipxFxICJei4hvTthmbTH+rYhYO903Js0F/tHXQjCVXUCPAzd/oXYP8GJmrgBeLJ4D3AKsKG7rgUdhPDCA+4BrgWuA+46HhiSpPk4bAJn5S+DQF8q3ATuKxzuA1RPqO3Pcr4ALIuJiYBWwOzMPZeZHwG6+HCqSpFk03YPAX8/M9wGK+68V9UuAdyaMGy5qX1WXJNXJmT4L6FSrYuUk9S9/g4j1EbE3IvYePHjwjDYnSfrcdAPgg2LXDsX9h0V9GLh0wrgW4L1J6l+SmY9lZntmti9fvnya7UmSTme6AbALOH4mz1rg5xPqa4qzgb4N/L7YRfQCcFNELCsO/t5U1CRJdXLai8JHRD/wPeCiiBhm/GyezcDTEdEFvA18vxj+HHArcAD4FPgRQGYeioi/BV4pxv1NZn7xwLIkaRY5EUwqYbKLv8zl3yVVi9cEliRNygCQpIoyACSpogwASaooA0CSKsoAkKSKMgAkqaIMAEmqKANAkirKAJCkijIAJKmiDABJqigDQJIqygCQpIoyACSpogwASaooA0CSKsoAkKSKMgAkqaIMAEmqKANAkirKAJCkijIAJKmiDABJqigDQJIqygCQpIoyACSpogwASaooA0CSKsoAkKSKMgAkqaJmFAAR8buIeD0iXo2IvUXtwojYHRFvFffLinpExE8j4kBEvBYR3zwTb0CSND1n4hNAR2ZelZntxfN7gBczcwXwYvEc4BZgRXFbDzx6Bl5bkjRNZ2MX0G3AjuLxDmD1hPrOHPcr4IKIuPgsvL4kaQpmGgAJ/N+I2BcR64va1zPzfYDi/mtF/RLgnQnbDhc1qe4iYkq3mX4PaS5ZNMPtv5uZ70XE14DdEfH/Jxl7qp/+/NKg8SBZD3DZZZfNsD1pajK/9KN4SpP9EZ/q95Dmihl9AsjM94r7D4F/BK4BPji+a6e4/7AYPgxcOmHzFuC9U3zPxzKzPTPbly9fPpP2JEmTmHYARERzRCw9/hi4CdgP7ALWFsPWAj8vHu8C1hRnA30b+P3xXUXSfPFV/+X737/mo5nsAvo68I/FR+JFwJOZ+U8R8QrwdER0AW8D3y/GPwfcChwAPgV+NIPXlurm+B/7iPAPv+a1aQdAZv4W+N+nqP8XcOMp6gn8eLqvJ0k6s5wJLEkVZQBIUkUZAJJUUQaAJFWUASBJFWUASFJFGQCSVFEGgCRVlAEgSRVlAEhSRRkAklRRBoAkVZQBIEkVNdMrgklz0oUXXshHH3101l/nbF/mcdmyZRw6dOisvoaqywDQgvTRRx8tiLX6vY6wziZ3AUlSRRkAklRRBoAkVZQBIEkVZQBIUkUZAJJUUZ4GqgUp7/sjuP/8ercxY3nfH9W7BS1gBoAWpPjrPyyYeQB5f7270ELlLiBJqigDQJIqyl1AWrAWwjIKy5Ytq3cLWsAMAC1Is7H/PyIWxHEGVZe7gCSpogwASaooA0CSKsoAkKSKMgAkqaJmPQAi4uaI+E1EHIiIe2b79SVJ42Y1ACKiEfg74BbgSqAzIq6czR4kSeNm+xPANcCBzPxtZn4GPAXcNss9SJKY/YlglwDvTHg+DFw7cUBErAfWA1x22WWz15kqbbqzhstu58QxzSWz/QngVL8tJ/1GZOZjmdmeme3Lly+fpbZUdZk5KzdpLpntABgGLp3wvAV4b5Z7kCQx+wHwCrAiIr4REecAPwB2zXIPkiRm+RhAZh6NiA3AC0Aj0JeZb8xmD5KkcbO+GmhmPgc8N9uvK0k6mTOBJamiDABJqigDQJIqygCQpIqKuTw5JSIOAv9R7z6kr3AR8J/1bkI6hf+RmaedSTunA0CayyJib2a217sPabrcBSRJFWUASFJFGQDS9D1W7wakmfAYgCRVlJ8AJKmiDACppIjoi4gPI2J/vXuRZsIAkMp7HLi53k1IM2UASCVl5i+BQ/XuQ5opA0CSKsoAkKSKMgAkqaIMAEmqKANAKiki+oH/B/zPiBiOiK569yRNhzOBJami/AQgSRVlAEhSRRkAklRRBoAkVZQBIEkVZQBIUkUZAJJUUQaAJFXUfwOyOvRbMT7SFAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.boxplot(review_lengths)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Result</b>\n",
    "Notice that the majority of the reviews contain less than 250 words. We will use this value later on when we pad / clip our reviews for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = df['review'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(50000,)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train = df.loc[:24999, 'review'].values\n",
    "y_train = df.loc[:24999, 'sentiment'].values\n",
    "x_test = df.loc[25000:, 'review'].values\n",
    "y_test = df.loc[25000:, 'sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n",
      "(25000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train.shape)\n",
    "print(y_train.shape)\n",
    "print(x_test.shape)\n",
    "print(y_test.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train_reviews = [len(x.split()) for x in x_train]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "25000"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(x_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 104,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "2278"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "max(x_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "228.52668"
      ]
     },
     "execution_count": 105,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.mean(x_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "168.88031504049727"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.std(x_train_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 109,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAYAAAAEICAYAAABWJCMKAAAABHNCSVQICAgIfAhkiAAAAAlwSFlzAAALEgAACxIB0t1+/AAAADl0RVh0U29mdHdhcmUAbWF0cGxvdGxpYiB2ZXJzaW9uIDMuMC4zLCBodHRwOi8vbWF0cGxvdGxpYi5vcmcvnQurowAAG+NJREFUeJzt3X+cXXV95/HXuwkgvyQJDBiTYEJJ1eAuGGchiFJKNAkBTexKje3CSLOb3T7iVl370GDrI8iPLXSrKLuVPlITDWiJEaWkhYXOhl9SBTLEEAiRZoCQDInJwITwIxUNfvaP853MyTh37r3z08z3/Xw87uOe8znfc+73nJl73/ece+65igjMzCw/vzXcHTAzs+HhADAzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwPpN0hWSvj3c/eiNpPMktQ3Qsq6W9IKknw3E8gaSpFMkvTrQbW1kcgCMMJIul3Rnt9qWCrUFQ9CfAXvhrfNxQ9Kpg7DcScBngWkR8ZZ+LutkSa+WbiHptdL4++tdZkQ8ExHHDHTbeqV1uy0F5V5Jj0u6pMZ5H5T0icHolx3MATDyPACcI2kUgKS3AIcB07vVTk1ta6ZC7v8zbwNejIjd9c4oaXR5PCK2RcQxnbdUPr1U+2EPyxjVt24Pue8AzwAnA8cDTUDd28wGV+5P5pFoHcUL/hlp/FzgXuCpbrWnI2IHgKT3SlqX3qmtk/TezoVJuk/SNZL+BdgHnCJpiqT7Jb0iqRk4oS8dlXSEpL+WtE3SLkl/K+nINO08SW2SPitpt6Sdki4rzXu8pH+U9HLq89WSHkzTOoPtsfRO+mOl+Sotb66kJ9M6PS/pz3ro7weAZuCtabnfSvUPS9ok6aW0vd5ZmmerpM9L2gi81j0EathG35b0N5LukvQa8P70eBtSX7dJ+mKp/amSojT+oKQvSfpRan+XpHH1tk3TL0uP94KkL6S/z3kVuv4fgG9GxL6I2B8R6yPi7tKyzpH0UNpmGySdm+rXAWcDf5u28Vfr2V5Wp4jwbYTdKF7wP5OG/w/wx8A13Wor0vA4YA9wCTAa+HgaPz5Nvw/YBpyWph8G/Bj4CnAERZi8Any7Ql/OA9oqTPsqsCb14VjgH4G/LM23H7gyPeZcigAam6avSrejgGnAduDB0rIDOLVbP3pb3k7g/Wl4LDC9lvUBfgd4DfhgWu7ngFbg8DR9K7ABmAQcWeXvdlCfU+3b6e9xNsUbtiOA84F3pfHTgReAi1L7U4un9YH5HwS2AFPTtvohcHUf2v679Hd+b+rD9Wl7nldhXe5L838MmNRt2iTgRWB2Woc5aR2OL/XjE8P9PMrh5j2Akel+ihdmgPdTPBF/2K12fxq+ENgSETdH8U7tFuCnwIdKy/tWRGyKiP3AeIp3d1+MiNcj4gGKF+66SBLwXyhCqSMiXgH+J1D+XOKXwJUR8cuIuBN4FXh7OgzyH4GlUbzDfBJYWcPD9ri80rRpkt4cEXsiYn2Nq/Ix4I6IaI6IXwJ/DRxJ8ULZ6YaI2B4R/1bjMru7LSJ+HBG/Stv8noh4Io0/RhGEv9vL/MsjYktE7AO+R9eeYD1tLwb+ISJ+FBGvA39Rpc+/T/FGYSnwnKT1kt6Tpl0KrImIu9M63AU8RhEENoQcACPTA8D7JI0FGiJiC/Aj4L2p9i66jv+/FXiu2/zPARNK49tLw28F9kTEa93a16uB4l3mo+kwwEvAXane6cUUOp32AcekNqO79as8XEml5UERKHMpXqzul3R2jetx0PaLiF+lvlTafn1x0PySzk6Hmtol7QX+M70fhiufrVRe53ravrXcj/T331NpISnUPxcR04CTgE3AbWny24CPd/7d099+RnoMG0IOgJHpx8BxwCLgXwAi4mVgR6rtiIhnU9sdFE/IspOB50vj5UvG7gTGSjq6W/t6vQD8G3BaRIxJt+OitrNS2ikOP0ws1Sb1oQ8HRMS6iJgHnAj8A7C6xlkP2n5pz2YSlbdfn7rXbXwV8H2KQyvHAd8A1M/HqGYnpe2d/v5ja5kxItqBLwOTJB1HESTfLP3dx0TE0RHxvzpnGeC+WwUOgBEoHWpoAf4HxaGfTg+mWvnsnzuB35H0h5JGpw9MpwH/VGHZz6Vlf0nS4ZLex8GHi3ok6U3lG8WT/O+A6yWdmNpMkDS7hvV7A/gBcIWkoyS9g+KwQtku4JRqy0qPe7ikP5J0XDqM8zLwRi3zUgTFhZJmSjqM4hTR1yn2uAbLsUBHRPxc0gwOPmw2WL4HzJc0Q9LhFJ+lVCTprySdJmmUpDcDfwL8NCL2AjcDH5H0wTT9TZJ+T1LnHkDNfzvrHwfAyHU/xbvZB0u1H6bagQCIiBeBiyheuF6k+BDzooh4oZdl/yFwFtBBcYz3pip9mUDxbr98+23g8xQfmD4k6WXg/9F1TL6aT1Ls5fyM4gXlFooX3k5XACvTIYY/qGF5lwBbUz/+G/CfaulERDyV2v5vir2aDwEfiohf1LgeffEnwF9KegX4ArXvrfRZRGwEPkMRBDso/lde5OBtXnYMcDuwF3ia4vDO/LSsrcBHgC9S7M1to/j/63w9+ipdh4i+MgirY4kivLdlh750+uBbIqJpuPuSg/Su/iXgbRHR3884bJh4D8AOSZLeIenfq3AmsJCuDxltEKTvHxwl6RiKY/rr/eJ/aHMA2KHqWIrPAV6jOATyZYpDDjZ4PkJx+KcNmEzxnRE7hPkQkJlZprwHYGaWqbquSzLUTjjhhJg8efJwd8PM7JDy6KOPvhARDdXa/UYHwOTJk2lpaRnubpiZHVIk1fTtfB8CMjPLVE0BIOkzKi53+4SkW9I396ZIeljFD4t8N307sPMSv9+V1JqmTy4t5/JUf6qWb3yamdngqRoAkiYAfwo0RsS7gFEUXz2/Drg+IqZSXBRqYZplIcXFwk6luGTsdWk509J8p1Fc9e/rOnR+3MLMbMSp9RDQaOBIFT9mcRTFhaHOB25N01eSvuYNzKPr0ry3AjPTBbLmAavS5WyfpbgEwJn9XwUzM+uLqgEQEc9TXON8G8UL/17gUeCl0qV12+i6/O0E0mVj0/S9FD8Jd6DewzwHSFokqUVSS3t7e1/WyczMalDLIaCxFO/ep1Bc0Olo4IIemnZ+o6yny9JGL/WDCxHLIqIxIhobGqqexWRmZn1UyyGgDwDPRkR7ulTuDyh+7WiMun7fdCLFV8SheGc/CQ78CPZxFFeNPFDvYR4zMxtitQTANmBGugiUgJnAkxS/O/vR1KaJruuwrEnjpOn3RHG9iTXAgnSW0BSK3x19ZGBWw8zM6lX1i2AR8bCkW4H1FL/C9BNgGXAHsErS1am2PM2yHLhZUivFO/8FaTmbJK2mCI/9wOL0wx5mZjYMfqMvBtfY2BjD9U3gyUvuqDht67UXDmFPzMzqI+nRiGis1s7fBDYzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsUw4AM7NMOQDMzDLlADAzy5QDwMwsU1UDQNLbJW0o3V6W9GlJ4yQ1S9qS7sem9pJ0g6RWSRslTS8tqym13yKpqfKjmpnZYKsaABHxVEScERFnAO8B9gG3AUuAtRExFVibxgEuAKam2yLgRgBJ44ClwFnAmcDSztAwM7OhV+8hoJnA0xHxHDAPWJnqK4H5aXgecFMUHgLGSBoPzAaaI6IjIvYAzcCcfq+BmZn1Sb0BsAC4JQ2fFBE7AdL9iak+Adhemqct1SrVDyJpkaQWSS3t7e11ds/MzGpVcwBIOhz4MPC9ak17qEUv9YMLEcsiojEiGhsaGmrtnpmZ1amePYALgPURsSuN70qHdkj3u1O9DZhUmm8isKOXupmZDYN6AuDjdB3+AVgDdJ7J0wTcXqpfms4GmgHsTYeI7gZmSRqbPvydlWpmZjYMRtfSSNJRwAeB/1oqXwuslrQQ2AZcnOp3AnOBVoozhi4DiIgOSVcB61K7KyOio99rYGZmfVJTAETEPuD4brUXKc4K6t42gMUVlrMCWFF/N83MbKD5m8BmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZplyAJiZZcoBYGaWKQeAmVmmHABmZpmqKQAkjZF0q6SfStos6WxJ4yQ1S9qS7semtpJ0g6RWSRslTS8tpym13yKpqfIjmpnZYKt1D+BrwF0R8Q7gdGAzsARYGxFTgbVpHOACYGq6LQJuBJA0DlgKnAWcCSztDA0zMxt6VQNA0puBc4HlABHxi4h4CZgHrEzNVgLz0/A84KYoPASMkTQemA00R0RHROwBmoE5A7o2ZmZWs1r2AE4B2oFvSvqJpG9IOho4KSJ2AqT7E1P7CcD20vxtqVapfhBJiyS1SGppb2+ve4XMzKw2tQTAaGA6cGNEvBt4ja7DPT1RD7XopX5wIWJZRDRGRGNDQ0MN3TMzs76oJQDagLaIeDiN30oRCLvSoR3S/e5S+0ml+ScCO3qpm5nZMKgaABHxM2C7pLen0kzgSWAN0HkmTxNwexpeA1yazgaaAexNh4juBmZJGps+/J2VamZmNgxG19juvwPfkXQ48AxwGUV4rJa0ENgGXJza3gnMBVqBfaktEdEh6SpgXWp3ZUR0DMhamJlZ3WoKgIjYADT2MGlmD20DWFxhOSuAFfV00MzMBoe/CWxmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlqmaAkDSVkmPS9ogqSXVxklqlrQl3Y9NdUm6QVKrpI2SppeW05Tab5HUVOnxzMxs8NWzB/B7EXFGRHT+NOQSYG1ETAXWpnGAC4Cp6bYIuBGKwACWAmcBZwJLO0PDzMyGXn8OAc0DVqbhlcD8Uv2mKDwEjJE0HpgNNEdER0TsAZqBOf14fDMz64daAyCAf5b0qKRFqXZSROwESPcnpvoEYHtp3rZUq1Q3M7NhMLrGdudExA5JJwLNkn7aS1v1UIte6gfPXATMIoCTTz65xu6ZmVm9atoDiIgd6X43cBvFMfxd6dAO6X53at4GTCrNPhHY0Uu9+2Mti4jGiGhsaGiob23MzKxmVQNA0tGSju0cBmYBTwBrgM4zeZqA29PwGuDSdDbQDGBvOkR0NzBL0tj04e+sVDMzs2FQyyGgk4DbJHW2//uIuEvSOmC1pIXANuDi1P5OYC7QCuwDLgOIiA5JVwHrUrsrI6JjwNbEzMzqUjUAIuIZ4PQe6i8CM3uoB7C4wrJWACvq76aZmQ00fxPYzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0zV8pvAAEgaBbQAz0fERZKmAKuAccB64JKI+IWkI4CbgPcALwIfi4itaRmXAwuBN4A/jYhD8kfhJy+5o9fpW6+9cIh6YmbWd/XsAXwK2Fwavw64PiKmAnsoXthJ93si4lTg+tQOSdOABcBpwBzg6ylUzMxsGNQUAJImAhcC30jjAs4Hbk1NVgLz0/C8NE6aPjO1nwesiojXI+JZoBU4cyBWwszM6lfrHsBXgc8Bv0rjxwMvRcT+NN4GTEjDE4DtAGn63tT+QL2HeQ6QtEhSi6SW9vb2OlbFzMzqUTUAJF0E7I6IR8vlHppGlWm9zdNViFgWEY0R0djQ0FCte2Zm1ke1fAh8DvBhSXOBNwFvptgjGCNpdHqXPxHYkdq3AZOANkmjgeOAjlK9U3keMzMbYlX3ACLi8oiYGBGTKT7EvSci/gi4F/hoatYE3J6G16Rx0vR7IiJSfYGkI9IZRFOBRwZsTczMrC41nwbag88DqyRdDfwEWJ7qy4GbJbVSvPNfABARmyStBp4E9gOLI+KNfjy+mZn1Q10BEBH3Afel4Wfo4SyeiPg5cHGF+a8Brqm3k2ZmNvD8TWAzs0z15xDQIa3at3nNzEY67wGYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlikHgJlZpqoGgKQ3SXpE0mOSNkn6UqpPkfSwpC2Svivp8FQ/Io23pumTS8u6PNWfkjR7sFbKzMyqq2UP4HXg/Ig4HTgDmCNpBnAdcH1ETAX2AAtT+4XAnog4Fbg+tUPSNIrfBz4NmAN8XdKogVwZMzOrXdUAiMKrafSwdAvgfODWVF8JzE/D89I4afpMSUr1VRHxekQ8C7TSw28Km5nZ0KjpMwBJoyRtAHYDzcDTwEsRsT81aQMmpOEJwHaANH0vcHy53sM85cdaJKlFUkt7e3v9a2RmZjWpKQAi4o2IOAOYSPGu/Z09NUv3qjCtUr37Yy2LiMaIaGxoaKile2Zm1gd1nQUUES8B9wEzgDGSOn9UfiKwIw23AZMA0vTjgI5yvYd5zMxsiNVyFlCDpDFp+EjgA8Bm4F7go6lZE3B7Gl6TxknT74mISPUF6SyhKcBU4JGBWhEzM6vP6OpNGA+sTGfs/BawOiL+SdKTwCpJVwM/AZan9suBmyW1UrzzXwAQEZskrQaeBPYDiyPijYFdHTMzq1XVAIiIjcC7e6g/Qw9n8UTEz4GLKyzrGuCa+rtpZmYDzd8ENjPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLlAPAzCxTDgAzs0w5AMzMMuUAMDPLVC2Xg7Y6TV5yR6/Tt1574RD1xMysMu8BmJllygFgZpYpB4CZWaYcAGZmmarlR+EnSbpX0mZJmyR9KtXHSWqWtCXdj011SbpBUqukjZKml5bVlNpvkdRU6THNzGzw1bIHsB/4bES8E5gBLJY0DVgCrI2IqcDaNA5wATA13RYBN0IRGMBS4CyK3xJe2hkaZmY29KoGQETsjIj1afgVYDMwAZgHrEzNVgLz0/A84KYoPASMkTQemA00R0RHROwBmoE5A7o2ZmZWs7o+A5A0GXg38DBwUkTshCIkgBNTswnA9tJsbalWqd79MRZJapHU0t7eXk/3zMysDjUHgKRjgO8Dn46Il3tr2kMteqkfXIhYFhGNEdHY0NBQa/fMzKxONQWApMMoXvy/ExE/SOVd6dAO6X53qrcBk0qzTwR29FI3M7NhUMtZQAKWA5sj4iulSWuAzjN5moDbS/VL09lAM4C96RDR3cAsSWPTh7+zUs3MzIZBLdcCOge4BHhc0oZU+wJwLbBa0kJgG3BxmnYnMBdoBfYBlwFERIekq4B1qd2VEdExIGthZmZ1qxoAEfEgPR+/B5jZQ/sAFldY1gpgRT0dNDOzweFvApuZZcoBYGaWKQeAmVmmHABmZplyAJiZZco/CTkMevvJSP9cpJkNFe8BmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpYpB4CZWaYcAGZmmXIAmJllygFgZpapEX0piN4uuWBmlruqASBpBXARsDsi3pVq44DvApOBrcAfRMSe9PvBX6P4Sch9wCciYn2apwn4i7TYqyNi5cCuyshQLbR8rSAzGyi1HAL6FjCnW20JsDYipgJr0zjABcDUdFsE3AgHAmMpcBZwJrA0/TC8mZkNk6oBEBEPAN1/vH0e0PkOfiUwv1S/KQoPAWMkjQdmA80R0RERe4Bmfj1UzMxsCPX1Q+CTImInQLo/MdUnANtL7dpSrVL910haJKlFUkt7e3sfu2dmZtUM9FlA6qEWvdR/vRixLCIaI6KxoaFhQDtnZmZd+hoAu9KhHdL97lRvAyaV2k0EdvRSNzOzYdLXAFgDNKXhJuD2Uv1SFWYAe9MhoruBWZLGpg9/Z6WamZkNk1pOA70FOA84QVIbxdk81wKrJS0EtgEXp+Z3UpwC2kpxGuhlABHRIekqYF1qd2VEdP9g2czMhlDVAIiIj1eYNLOHtgEsrrCcFcCKunpnZmaDZkR/E3gk8g/Km9lA8bWAzMwy5QAwM8uUA8DMLFMOADOzTDkAzMwy5bOARhBfStrM6uE9ADOzTDkAzMwy5UNAGfEhIjMr8x6AmVmmHABmZpnyISA7wNcZMsuL9wDMzDLlADAzy5QPAVlNfAaR2cjjALAB4c8PzA49DgAbdN57MPvNNOQBIGkO8DVgFPCNiLh2qPtgv1n6ExDV5q3G4WM5G9IAkDQK+Bvgg0AbsE7Smoh4cij7YYeW/r7Im1nPhvosoDOB1oh4JiJ+AawC5g1xH8zMjKE/BDQB2F4abwPOKjeQtAhYlEZflfRUHx/rBOCFPs470nhbdDloW+i6YezJ8PP/RZeRti3eVkujoQ4A9VCLg0YilgHL+v1AUktENPZ3OSOBt0UXb4su3hZdct0WQ30IqA2YVBqfCOwY4j6YmRlDHwDrgKmSpkg6HFgArBniPpiZGUN8CCgi9kv6JHA3xWmgKyJi0yA9XL8PI40g3hZdvC26eFt0yXJbKCKqtzIzsxHHF4MzM8uUA8DMLFMjMgAkzZH0lKRWSUuGuz+DTdJWSY9L2iCpJdXGSWqWtCXdj011SbohbZuNkqYPb+/7R9IKSbslPVGq1b3ukppS+y2SmoZjXfqrwra4QtLz6X9jg6S5pWmXp23xlKTZpfoh//yRNEnSvZI2S9ok6VOpnuX/RkURMaJuFB8uPw2cAhwOPAZMG+5+DfI6bwVO6Fb7K2BJGl4CXJeG5wL/l+I7GTOAh4e7//1c93OB6cATfV13YBzwTLofm4bHDve6DdC2uAL4sx7aTkvPjSOAKek5M2qkPH+A8cD0NHws8K9pnbP836h0G4l7AL7cRGEesDINrwTml+o3ReEhYIyk8cPRwYEQEQ8AHd3K9a77bKA5IjoiYg/QDMwZ/N4PrArbopJ5wKqIeD0ingVaKZ47I+L5ExE7I2J9Gn4F2ExxJYIs/zcqGYkB0NPlJiYMU1+GSgD/LOnRdCkNgJMiYicUTwbgxFTPYfvUu+4jfZt8Mh3WWNF5yIOMtoWkycC7gYfx/8ZBRmIAVL3cxAh0TkRMBy4AFks6t5e2OW6fTpXWfSRvkxuB3wbOAHYCX071LLaFpGOA7wOfjoiXe2vaQ23EbY/uRmIAZHe5iYjYke53A7dR7Mbv6jy0k+53p+Y5bJ96133EbpOI2BURb0TEr4C/o/jfgAy2haTDKF78vxMRP0hl/2+UjMQAyOpyE5KOlnRs5zAwC3iCYp07z1hoAm5Pw2uAS9NZDzOAvZ27xCNIvet+NzBL0th0iGRWqh3yun2+8xGK/w0otsUCSUdImgJMBR5hhDx/JAlYDmyOiK+UJvl/o2y4P4UejBvFJ/r/SnE2w58Pd38GeV1PoThT4zFgU+f6AscDa4Et6X5cqoviR3meBh4HGod7Hfq5/rdQHNr4JcW7tYV9WXfgjyk+CG0FLhvu9RrAbXFzWteNFC9y40vt/zxti6eAC0r1Q/75A7yP4lDNRmBDus3N9X+j0s2XgjAzy9RIPARkZmY1cACYmWXKAWBmlikHgJlZphwAZmaZcgCYmWXKAWBmlqn/D8UMpcoMDahjAAAAAElFTkSuQmCC\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "plt.hist(x_train_reviews, bins=40)  # arguments are passed to np.histogram\n",
    "plt.title(\"Word Lengths for Training Set\")\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Check</b>: Wanted to double check that the training data shared similar characteristics to the overall dataset. It seems that they are so we can proceed."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([0, 1])"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.unique(y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([12500, 12500])"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.bincount(y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "import keras\n",
    "from keras.preprocessing.text import Tokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b> Although we saw that the mean word length is 230, our model had trouble training properly. As such I tried a smaller max_len value and with max_len = 80, the model's accuracy improved significantly."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(vocab)\n",
    "\n",
    "# max_len = max([len(s.split()) for s in vocab])\n",
    "max_len = 80\n",
    "\n",
    "vocab_size = len(tokenizer.word_index) + 1\n",
    "\n",
    "x_train_tokens = tokenizer.texts_to_sequences(x_train)\n",
    "x_test_tokens = tokenizer.texts_to_sequences(x_test)\n",
    "\n",
    "x_train_pad = pad_sequences(x_train_tokens, maxlen = max_len, padding = 'post')\n",
    "x_test_pad = pad_sequences(x_test_tokens, maxlen = max_len, padding = 'post')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "80\n",
      "80\n",
      "80\n"
     ]
    }
   ],
   "source": [
    "print(max_len)\n",
    "print(len(x_train_pad[0]))\n",
    "print(len(x_train_pad[1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000, 80)"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train_pad.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(25000,)"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_train.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we've tokenized all the words in the movie reviews dataset. This means that every word is now identifiable by an index. This makes it possible to train for word embeddings. We've padded each sentence so that they will all be of the same length."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Note</b>: The embedding layer requires the vocab size, dimension of the dense embedding and we will be using input_length"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Model</h2>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Embedding, Dense, LSTM, GRU\n",
    "from keras.layers.embeddings import Embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Stephen-Mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/framework/op_def_library.py:263: colocate_with (from tensorflow.python.framework.ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Colocations handled automatically by placer.\n",
      "WARNING:tensorflow:From /Users/Stephen-Mac/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py:3445: calling dropout (from tensorflow.python.ops.nn_ops) with keep_prob is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `rate` instead of `keep_prob`. Rate should be set to `rate = 1 - keep_prob`.\n"
     ]
    }
   ],
   "source": [
    "EMBEDDING_DIM = 100\n",
    "\n",
    "model = Sequential()\n",
    "model.add(Embedding(vocab_size, EMBEDDING_DIM, input_length=max_len))\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_1 (Embedding)      (None, 80, 100)           12425300  \n",
      "_________________________________________________________________\n",
      "gru_1 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_1 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 12,438,101\n",
      "Trainable params: 12,438,101\n",
      "Non-trainable params: 0\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /Users/Stephen-Mac/anaconda3/lib/python3.6/site-packages/tensorflow/python/ops/math_ops.py:3066: to_int32 (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use tf.cast instead.\n",
      "Train on 25000 samples, validate on 25000 samples\n",
      "Epoch 1/25\n",
      "25000/25000 [==============================] - 262s 10ms/step - loss: 0.5505 - acc: 0.7092 - val_loss: 0.4565 - val_acc: 0.7871\n",
      "Epoch 2/25\n",
      "25000/25000 [==============================] - 188s 8ms/step - loss: 0.3409 - acc: 0.8609 - val_loss: 0.4286 - val_acc: 0.8084\n",
      "Epoch 3/25\n",
      "25000/25000 [==============================] - 191s 8ms/step - loss: 0.2408 - acc: 0.9074 - val_loss: 0.4464 - val_acc: 0.8130\n",
      "Epoch 4/25\n",
      "25000/25000 [==============================] - 205s 8ms/step - loss: 0.1763 - acc: 0.9374 - val_loss: 0.4920 - val_acc: 0.8081\n",
      "Epoch 5/25\n",
      "25000/25000 [==============================] - 186s 7ms/step - loss: 0.1246 - acc: 0.9572 - val_loss: 0.5457 - val_acc: 0.8040\n",
      "Epoch 6/25\n",
      "16640/25000 [==================>...........] - ETA: 58s - loss: 0.0837 - acc: 0.9724"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-19-faeff620ddf3>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train_pad, y_train, batch_size=128, epochs=25, validation_data=(x_test_pad, y_test))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "test1 = \"this is a new sentence\"\n",
    "test2 = \"I hate you\"\n",
    "test3 = \"I love you\"\n",
    "\n",
    "test_sample = [test1, test2, test3]\n",
    "\n",
    "test_samples_tokens = tokenizer.texts_to_sequences(test_sample)\n",
    "test_samples_tokens_pad = pad_sequences(test_samples_tokens, maxlen=max_len, padding='post')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[  11,    6,    3,  168, 3645,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0],\n",
       "       [  10,  737,   22,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0],\n",
       "       [  10,  112,   22,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0,    0,    0,    0,    0,    0,    0,    0,    0,\n",
       "           0,    0,    0]], dtype=int32)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_samples_tokens_pad"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.9650962 ],\n",
       "       [0.9647652 ],\n",
       "       [0.97078216]], dtype=float32)"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.predict(x=test_samples_tokens_pad)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "25000/25000 [==============================] - 48s 2ms/step\n",
      "Accuracy: 79.73%\n"
     ]
    }
   ],
   "source": [
    "scores = model.evaluate(x_test_pad, y_test)\n",
    "print(\"Accuracy: %.2f%%\" % (scores[1]*100))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings = model.layers[0].get_weights()[0]\n",
    "\n",
    "word_embeddings = {w:embeddings[index] for w, index in tokenizer.word_index.items()}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [],
   "source": [
    "def cosine_similarity(emb1, emb2):\n",
    "    numerator = np.dot(emb1, emb2)\n",
    "    norm_emb1 = np.sqrt(np.dot(emb1, emb1))\n",
    "    norm_emb2 = np.sqrt(np.dot(emb2, emb2))\n",
    "    cosine_sim = np.divide(numerator, norm_emb1*norm_emb2)\n",
    "    \n",
    "    return cosine_sim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "hero, villain:  -0.379964\n",
      "love, hate:  -0.107931\n",
      "fantastic, wonderful:  0.791935\n",
      "beautiful, ugly:  -0.487247\n",
      "great, horrible:  -0.712698\n",
      "evil, monster:  0.301039\n",
      "evil, villain:  -0.309882\n"
     ]
    }
   ],
   "source": [
    "# test our word embeddings using cosine similarity\n",
    "\n",
    "print(\"hero, villain:  %f\" %(cosine_similarity(word_embeddings['hero'], word_embeddings['villain'])))\n",
    "print(\"love, hate:  %f\" %(cosine_similarity(word_embeddings['love'], word_embeddings['hate'])))\n",
    "print(\"fantastic, wonderful:  %f\" %(cosine_similarity(word_embeddings['fantastic'], word_embeddings['wonderful'])))\n",
    "print(\"beautiful, ugly:  %f\" %(cosine_similarity(word_embeddings['beautiful'], word_embeddings['ugly'])))\n",
    "print(\"great, horrible:  %f\" %(cosine_similarity(word_embeddings['great'], word_embeddings['horrible'])))\n",
    "print(\"evil, monster:  %f\" %(cosine_similarity(word_embeddings['evil'], word_embeddings['monster'])))\n",
    "print(\"evil, villain:  %f\" %(cosine_similarity(word_embeddings['evil'], word_embeddings['villain'])))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<b>Self trained word embeddings:</b>\n",
    "After just a few epochs it seems like the model has learned some relations between words. It is more confident in adjectives which is probably due to the training data provided. For regular nouns it is not as accurate. Thus, it seems it is more viable to start with some pre-trained embeddings than to learn them from scratch on this inbalanced dataset."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Try loading in pre-trained word embeddings</h2>\n",
    "\n",
    "<p>We will be using Genism's implementation of Word2Vec. We need to format our reviews so that it is trainable by their algorithm.</p>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "import string \n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "cleaned_reviews = list()\n",
    "\n",
    "reviews = df['review'].values.tolist()\n",
    "\n",
    "stop_words = set(stopwords.words('english'))\n",
    "punc_table = str.maketrans('', '', string.punctuation)\n",
    "\n",
    "for review in reviews:\n",
    "    tokens = word_tokenize(review)\n",
    "    tokens = [w.lower() for w in tokens]\n",
    "    stripped = [w.translate(punc_table) for w in tokens]\n",
    "    words = [word for word in stripped if word.isalpha()]\n",
    "    words = [w for w in words if not w in stop_words]\n",
    "    cleaned_reviews.append(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "50000"
      ]
     },
     "execution_count": 50,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(cleaned_reviews)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['went',\n",
       " 'saw',\n",
       " 'movie',\n",
       " 'last',\n",
       " 'night',\n",
       " 'coaxed',\n",
       " 'friends',\n",
       " 'mine',\n",
       " 'admit',\n",
       " 'reluctant',\n",
       " 'see',\n",
       " 'knew',\n",
       " 'ashton',\n",
       " 'kutcher',\n",
       " 'able',\n",
       " 'comedy',\n",
       " 'wrong',\n",
       " 'kutcher',\n",
       " 'played',\n",
       " 'character',\n",
       " 'jake',\n",
       " 'fischer',\n",
       " 'well',\n",
       " 'kevin',\n",
       " 'costner',\n",
       " 'played',\n",
       " 'ben',\n",
       " 'randall',\n",
       " 'professionalism',\n",
       " 'sign',\n",
       " 'good',\n",
       " 'movie',\n",
       " 'toy',\n",
       " 'emotions',\n",
       " 'one',\n",
       " 'exactly',\n",
       " 'entire',\n",
       " 'theater',\n",
       " 'sold',\n",
       " 'overcome',\n",
       " 'laughter',\n",
       " 'first',\n",
       " 'half',\n",
       " 'movie',\n",
       " 'moved',\n",
       " 'tears',\n",
       " 'second',\n",
       " 'half',\n",
       " 'exiting',\n",
       " 'theater',\n",
       " 'saw',\n",
       " 'many',\n",
       " 'women',\n",
       " 'tears',\n",
       " 'many',\n",
       " 'full',\n",
       " 'grown',\n",
       " 'men',\n",
       " 'well',\n",
       " 'trying',\n",
       " 'desperately',\n",
       " 'let',\n",
       " 'anyone',\n",
       " 'see',\n",
       " 'crying',\n",
       " 'movie',\n",
       " 'great',\n",
       " 'suggest',\n",
       " 'go',\n",
       " 'see',\n",
       " 'judge']"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "cleaned_reviews[0]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "genism's Word2Vec requires sentences - list of lists of tokens, size which is the embedding dim size, window - distance between current and predicted words within a sentence, min_count - how many occurences required"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "134121\n"
     ]
    }
   ],
   "source": [
    "import gensim \n",
    "\n",
    "model = gensim.models.Word2Vec(sentences = cleaned_reviews, size=EMBEDDING_DIM, window=5, min_count=1)\n",
    "\n",
    "words = list(model.wv.vocab)\n",
    "\n",
    "print(len(words))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('dorff', 0.8209315538406372),\n",
       " ('edgar', 0.8183038830757141),\n",
       " ('lear', 0.7838637828826904),\n",
       " ('timothy', 0.7785831689834595),\n",
       " ('samuel', 0.7767901420593262),\n",
       " ('leonard', 0.7743215560913086),\n",
       " ('arthur', 0.7678720355033875),\n",
       " ('l', 0.7671722173690796),\n",
       " ('burroughs', 0.76711106300354),\n",
       " ('avery', 0.7669883966445923)]"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar(\"stephen\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('fantastic', 1.1092069149017334),\n",
       " ('wonderful', 1.108721137046814),\n",
       " ('gershwyn', 1.0737359523773193),\n",
       " ('seenjust', 1.0718988180160522),\n",
       " ('amazing', 1.0539801120758057),\n",
       " ('eversoshort', 1.0534483194351196),\n",
       " ('richlycoloured', 1.0502643585205078),\n",
       " ('lessthensuccessful', 1.0319212675094604),\n",
       " ('jungleadventure', 1.029566764831543),\n",
       " ('faield', 1.0271861553192139)]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.most_similar_cosmul(positive=['love', 'beautiful'], negative=['woman'])\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'movie'"
      ]
     },
     "execution_count": 100,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.wv.doesnt_match(\"chocolate candy salad movie\".split())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Save our embeddings</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "filename = 'imdb_embedding_word2vec.txt'\n",
    "model.wv.save_word2vec_format(filename, binary=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Load pretraind embeddings</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "\n",
    "embeddings_index = {}\n",
    "\n",
    "f = open(os.path.join('', 'imdb_embedding_word2vec.txt'), encoding=\"utf-8\")\n",
    "for line in f:\n",
    "    values = line.split()\n",
    "    word = values[0]\n",
    "    coefs = np.asarray(values[1:]) # asarray converts its input into an array\n",
    "    embeddings_index[word] = coefs\n",
    "\n",
    "f.close()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = Tokenizer()\n",
    "tokenizer.fit_on_texts(cleaned_reviews)\n",
    "sequences = tokenizer.texts_to_sequences(cleaned_reviews)\n",
    "\n",
    "word_index = tokenizer.word_index"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [],
   "source": [
    "num_words = len(word_index) + 1\n",
    "embedding_matrix = np.zeros((num_words, EMBEDDING_DIM))\n",
    "\n",
    "for word, i in word_index.items():\n",
    "    if i > num_words:\n",
    "        continue\n",
    "    embedding_vector = embeddings_index.get(word)\n",
    "    if embedding_vector is not None:\n",
    "        embedding_matrix[i] = embedding_vector"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h3>Now we just need to load our embeddings into the model and learn</h3>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [],
   "source": [
    "from keras.models import Sequential\n",
    "from keras.layers import Dense, Embedding, GRU, LSTM\n",
    "from keras.layers.embeddings import Embedding\n",
    "from keras.initializers import Constant"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 105,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "\n",
    "embedding_layer = Embedding(num_words, EMBEDDING_DIM, embeddings_initializer=Constant(embedding_matrix), input_length=max_len, trainable=False)\n",
    "model.add(embedding_layer)\n",
    "model.add(GRU(units=32, dropout=0.2, recurrent_dropout=0.2))\n",
    "model.add(Dense(1, activation='sigmoid'))\n",
    "\n",
    "model.compile(loss='binary_crossentropy', optimizer='adam', metrics=['accuracy'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "_________________________________________________________________\n",
      "Layer (type)                 Output Shape              Param #   \n",
      "=================================================================\n",
      "embedding_3 (Embedding)      (None, 2470, 100)         13412200  \n",
      "_________________________________________________________________\n",
      "gru_3 (GRU)                  (None, 32)                12768     \n",
      "_________________________________________________________________\n",
      "dense_3 (Dense)              (None, 1)                 33        \n",
      "=================================================================\n",
      "Total params: 13,425,001\n",
      "Trainable params: 12,801\n",
      "Non-trainable params: 13,412,200\n",
      "_________________________________________________________________\n"
     ]
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 108,
   "metadata": {},
   "outputs": [],
   "source": [
    "review_pad = pad_sequences(sequences, maxlen=max_len)\n",
    "sentiment = df['sentiment'].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 121,
   "metadata": {},
   "outputs": [],
   "source": [
    "VALIDATION_SPLIT = 0.2\n",
    "\n",
    "# this shuffles the dataset\n",
    "indices = np.arange(review_pad.shape[0])\n",
    "np.random.shuffle(indices)\n",
    "review_pad = review_pad[indices]\n",
    "sentiment = sentiment[indices]\n",
    "\n",
    "num_validation_samples = int(VALIDATION_SPLIT * review_pad.shape[0])\n",
    "\n",
    "x_train_pad = review_pad[:-num_validation_samples]\n",
    "y_train_pad = sentiment[:-num_validation_samples]\n",
    "x_test_pad = review_pad[-num_validation_samples:]\n",
    "y_test_pad = sentiment[-num_validation_samples:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(40000, 2470)\n",
      "(40000,)\n",
      "(10000, 2470)\n",
      "(10000,)\n"
     ]
    }
   ],
   "source": [
    "print(x_train_pad.shape)\n",
    "print(y_train_pad.shape)\n",
    "print(x_test_pad.shape)\n",
    "print(y_test_pad.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train on 40000 samples, validate on 10000 samples\n",
      "Epoch 1/25\n",
      " 1152/40000 [..............................] - ETA: 1:15:06 - loss: 0.7257 - acc: 0.5312"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-123-cb0780c8dcfd>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_train_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mbatch_size\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m128\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mepochs\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;36m25\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mvalidation_data\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx_test_pad\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_test_pad\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training.py\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, x, y, batch_size, epochs, verbose, callbacks, validation_split, validation_data, shuffle, class_weight, sample_weight, initial_epoch, steps_per_epoch, validation_steps, **kwargs)\u001b[0m\n\u001b[1;32m   1037\u001b[0m                                         \u001b[0minitial_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0minitial_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1038\u001b[0m                                         \u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msteps_per_epoch\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1039\u001b[0;31m                                         validation_steps=validation_steps)\n\u001b[0m\u001b[1;32m   1040\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1041\u001b[0m     def evaluate(self, x=None, y=None,\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/engine/training_arrays.py\u001b[0m in \u001b[0;36mfit_loop\u001b[0;34m(model, f, ins, out_labels, batch_size, epochs, verbose, callbacks, val_f, val_ins, shuffle, callback_metrics, initial_epoch, steps_per_epoch, validation_steps)\u001b[0m\n\u001b[1;32m    197\u001b[0m                     \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mins_batch\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtoarray\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    198\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 199\u001b[0;31m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mf\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mins_batch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    200\u001b[0m                 \u001b[0mouts\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mto_list\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    201\u001b[0m                 \u001b[0;32mfor\u001b[0m \u001b[0ml\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mo\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mzip\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mout_labels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mouts\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2713\u001b[0m                 \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_legacy_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2714\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2715\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2716\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2717\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0mpy_any\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mis_tensor\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0minputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/keras/backend/tensorflow_backend.py\u001b[0m in \u001b[0;36m_call\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m   2673\u001b[0m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mrun_metadata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2674\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2675\u001b[0;31m             \u001b[0mfetched\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_callable_fn\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0marray_vals\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2676\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mfetched\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0moutputs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2677\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/anaconda3/lib/python3.6/site-packages/tensorflow/python/client/session.py\u001b[0m in \u001b[0;36m__call__\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1437\u001b[0m           ret = tf_session.TF_SessionRunCallable(\n\u001b[1;32m   1438\u001b[0m               \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_session\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_handle\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mstatus\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1439\u001b[0;31m               run_metadata_ptr)\n\u001b[0m\u001b[1;32m   1440\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mrun_metadata\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1441\u001b[0m           \u001b[0mproto_data\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtf_session\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mTF_GetBuffer\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrun_metadata_ptr\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "model.fit(x_train_pad, y_train_pad, batch_size=128, epochs=25, validation_data=(x_test_pad, y_test_pad))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<h2>Conclusion</h2>\n",
    "\n",
    "In this notebook I covered learning a word embedding while training a network on a sentiment classification. Then I tried loading a pre-trained embedding and then training it with the IMDB reviews word vocabulary. Finally, I used this pre-trained embedding for my embedding layer of my neural network. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
